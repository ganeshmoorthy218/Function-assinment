{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Q1.What is a random variable in probability theory?\n",
        "- A **random variable** in probability theory is a function that assigns a numerical value to each outcome in a sample space of a random experiment. It can be:\n",
        "\n",
        "* **Discrete**: Takes on a countable number of values (e.g., number of heads in coin tosses).\n",
        "* **Continuous**: Takes on any value within a range (e.g., time, weight).\n",
        "\n",
        "Random variables help quantify uncertainty and are used to define probability distributions.\n"
      ],
      "metadata": {
        "id": "MhBw1Hv6YW5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q2.What are the types of random variables?\n",
        "- There are **two main types of random variables**:\n",
        "\n",
        "1. **Discrete Random Variable**\n",
        "\n",
        "   * Takes on a **countable** number of distinct values.\n",
        "   * Example: Number of students in a class, dice rolls.\n",
        "\n",
        "2. **Continuous Random Variable**\n",
        "\n",
        "   * Takes on an **uncountable** number of possible values within a range (usually real numbers).\n",
        "   * Example: Height of a person, time taken to run a race.\n",
        "\n",
        "These two types differ mainly in the nature of the values they can assume and the way their probabilities are described (probability mass function for discrete, probability density function for continuous).\n"
      ],
      "metadata": {
        "id": "b_dwgCAKYm5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q3.What is the difference between discrete and continuous distributions?\n",
        "- The **difference between discrete and continuous distributions** lies in the type of values the random variable can take and how probabilities are assigned:\n",
        "\n",
        "| Feature                    | **Discrete Distribution**                   | **Continuous Distribution**                       |\n",
        "| -------------------------- | ------------------------------------------- | ------------------------------------------------- |\n",
        "| **Values**                 | Countable (e.g., 0, 1, 2, …)                | Uncountably infinite (e.g., any real number)      |\n",
        "| **Probability Assignment** | Uses a **Probability Mass Function (PMF)**  | Uses a **Probability Density Function (PDF)**     |\n",
        "| **Probability of a value** | $P(X = x) > 0$ for some specific values     | $P(X = x) = 0$ for any exact value                |\n",
        "| **Examples**               | Number of heads in 3 coin tosses, dice roll | Time to complete a task, temperature measurements |\n",
        "| **Graph Type**             | Bar graph (discrete points)                 | Smooth curve (area under curve gives probability) |\n",
        "\n",
        "In short:\n",
        "\n",
        "* **Discrete** = probabilities assigned to individual points.\n",
        "* **Continuous** = probabilities assigned over intervals (area under the curve).\n"
      ],
      "metadata": {
        "id": "0-F0DRFyYuNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q4.What are probability distribution functions (PDF)?\n",
        "- A **Probability Distribution Function (PDF)** describes how probabilities are distributed over the values of a **random variable**.\n",
        "\n",
        "There are two main types, depending on the type of random variable:\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Probability Mass Function (PMF)** – for **Discrete** Random Variables\n",
        "\n",
        "* Gives the **probability that a discrete random variable is exactly equal to a specific value**.\n",
        "* Example:\n",
        "  For a fair die,\n",
        "  $P(X = 3) = \\frac{1}{6}$\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Probability Density Function (PDF)** – for **Continuous** Random Variables\n",
        "\n",
        "* Describes the **relative likelihood** of a random variable taking on a value in a continuous range.\n",
        "* For a continuous variable, $P(X = x) = 0$; we only compute probabilities over intervals:\n",
        "\n",
        "  $$\n",
        "  P(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx\n",
        "  $$\n",
        "\n",
        "  where $f(x)$ is the PDF.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary:\n",
        "\n",
        "* **PMF** gives actual probabilities for **discrete** outcomes.\n",
        "* **PDF** gives **density** for **continuous** outcomes—probabilities are found by integrating over a range.\n"
      ],
      "metadata": {
        "id": "PrKc7XjAY7DB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q5. How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)?\n",
        "- The **PDF (or PMF)** gives the **probability at a specific value** (PDF for continuous, PMF for discrete). The **CDF** gives the **cumulative probability** that a random variable is **less than or equal to a certain value**.\n",
        "\n",
        "In short:\n",
        "\n",
        "* **PDF/PMF**: $P(X = x)$\n",
        "* **CDF**: $P(X \\leq x)$\n",
        "\n",
        "CDF is the running total (sum or integral) of the PDF/PMF.\n"
      ],
      "metadata": {
        "id": "1-0gaEZvZFnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q6.What is a discrete uniform distribution?\n",
        "- A **discrete uniform distribution** is a probability distribution where **all outcomes are equally likely** over a **finite set** of values.\n",
        "\n",
        "If a random variable $X$ can take $n$ distinct values $x_1, x_2, ..., x_n$, then:\n",
        "\n",
        "$$\n",
        "P(X = x_i) = \\frac{1}{n} \\quad \\text{for all } i\n",
        "$$\n",
        "\n",
        "**Example**: Rolling a fair six-sided die — each face (1 to 6) has a probability of $\\frac{1}{6}$.\n"
      ],
      "metadata": {
        "id": "i8UtKnEnZae0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q7.= What are the key properties of a Bernoulli distribution?\n",
        "- The **Bernoulli distribution** models a random experiment with **only two outcomes**: success (1) and failure (0).\n",
        "\n",
        "### Key Properties:\n",
        "\n",
        "* **Outcomes**: 0 or 1\n",
        "* **Parameter**: $p$ = probability of success (0 ≤ $p$ ≤ 1)\n",
        "* **Mean (Expected value)**: $E[X] = p$\n",
        "* **Variance**: $\\text{Var}(X) = p(1 - p)$\n",
        "\n",
        "**Example**: Tossing a coin where heads = 1 (success), tails = 0 (failure).\n"
      ],
      "metadata": {
        "id": "keGjfyD1ZjtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q8.What is the binomial distribution, and how is it used in probability?\n",
        "- The **binomial distribution** models the number of **successes** in a fixed number of **independent trials**, each with the same probability of success.\n",
        "\n",
        "### Key Features:\n",
        "\n",
        "* **Parameters**:\n",
        "\n",
        "  * $n$: Number of trials\n",
        "  * $p$: Probability of success on each trial\n",
        "* **Probability mass function (PMF)**:\n",
        "\n",
        "  $$\n",
        "  P(X = k) = \\binom{n}{k} p^k (1 - p)^{n-k}\n",
        "  $$\n",
        "\n",
        "  where $k$ is the number of successes (from 0 to $n$).\n",
        "\n",
        "### Usage:\n",
        "\n",
        "It is used to calculate the likelihood of a certain number of successes (e.g., flipping 3 heads in 5 coin tosses) in a fixed number of independent trials.\n"
      ],
      "metadata": {
        "id": "1mO8HCkWZr6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q9.What is the Poisson distribution and where is it applied?\n",
        "- The **Poisson distribution** models the **number of events** occurring in a fixed interval of time or space, given that events happen **independently** and at a **constant average rate**.\n",
        "\n",
        "### Key Features:\n",
        "\n",
        "* **Parameter**: $\\lambda$ (average rate of occurrences per interval)\n",
        "* **Probability mass function (PMF)**:\n",
        "\n",
        "  $$\n",
        "  P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
        "  $$\n",
        "\n",
        "  where $k$ is the number of events.\n",
        "\n",
        "### Applications:\n",
        "\n",
        "The Poisson distribution is used in scenarios like:\n",
        "\n",
        "* Number of phone calls at a call center per hour.\n",
        "* Number of accidents at an intersection in a day.\n",
        "* Number of emails received in an hour.\n"
      ],
      "metadata": {
        "id": "7l-uNl2-Z3Jq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q10.What is a continuous uniform distribution?\n",
        "- A **continuous uniform distribution** describes a random variable that has **equal probability** of taking any value within a specific **continuous interval**.\n",
        "\n",
        "### Key Features:\n",
        "\n",
        "* **Interval**: $[a, b]$, where $a$ is the minimum value and $b$ is the maximum value.\n",
        "* **Probability density function (PDF)**:\n",
        "\n",
        "  $$\n",
        "  f(x) = \\frac{1}{b - a} \\quad \\text{for } a \\leq x \\leq b\n",
        "  $$\n",
        "* **Mean**: $\\mu = \\frac{a + b}{2}$\n",
        "* **Variance**: $\\sigma^2 = \\frac{(b - a)^2}{12}$\n",
        "\n",
        "### Example:\n",
        "\n",
        "The random variable $X$ representing the time a bus arrives, uniformly distributed between 0 and 10 minutes.\n"
      ],
      "metadata": {
        "id": "hW2qFH2_Z_HL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q11.What are the characteristics of a normal distribution?\n",
        "\n",
        "- The **normal distribution** is a continuous probability distribution that is symmetric and bell-shaped.\n",
        "\n",
        "### Key Characteristics:\n",
        "\n",
        "* **Symmetry**: It is symmetric around its mean ($\\mu$).\n",
        "* **Mean, Median, Mode**: All are equal and located at the center.\n",
        "* **Shape**: Bell-shaped, with the highest point at the mean.\n",
        "* **Spread**: The spread is determined by the standard deviation ($\\sigma$). Larger $\\sigma$ means a wider distribution.\n",
        "* **68-95-99.7 Rule**: Approximately 68% of values lie within 1 standard deviation of the mean, 95% within 2, and 99.7% within 3.\n",
        "\n",
        "It is widely used to model natural phenomena like heights, test scores, and measurement errors.\n"
      ],
      "metadata": {
        "id": "0d4EVHI0aMi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q12.What is the standard normal distribution, and why is it important?\n",
        "- The **standard normal distribution** is a special case of the normal distribution with a **mean of 0** and a **standard deviation of 1**. It is denoted as $Z$, where:\n",
        "\n",
        "* **Mean ($\\mu$)** = 0\n",
        "* **Standard deviation ($\\sigma$)** = 1\n",
        "\n",
        "### Importance:\n",
        "\n",
        "* It simplifies calculations by allowing data to be transformed into **z-scores**, which represent how many standard deviations a value is from the mean.\n",
        "* The standard normal distribution is crucial for **hypothesis testing**, **confidence intervals**, and other statistical analyses.\n",
        "* It provides a reference for probabilities using standard normal tables (z-tables).\n"
      ],
      "metadata": {
        "id": "Pvbd5Y-xaXBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q13.What is the Central Limit Theorem (CLT), and why is it critical in statistics?\n",
        "- The **Central Limit Theorem (CLT)** states that the **sampling distribution of the sample mean** approaches a **normal distribution** as the sample size increases, regardless of the shape of the original population distribution, provided the samples are independent and identically distributed (i.i.d.).\n",
        "\n",
        "### Importance:\n",
        "\n",
        "* **CLT** allows statisticians to use the normal distribution as an approximation for the sample mean, even if the population is not normally distributed.\n",
        "* It is critical for performing **hypothesis tests**, constructing **confidence intervals**, and making **inferences** from sample data, especially when sample sizes are large.\n"
      ],
      "metadata": {
        "id": "U82neBZ6agEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q14. How does the Central Limit Theorem relate to the normal distribution?\n",
        "- The **Central Limit Theorem (CLT)** explains that, regardless of the original population's distribution, the distribution of the **sample mean** will approximate a **normal distribution** as the sample size increases, typically when the sample size is **n ≥ 30**.\n",
        "\n",
        "### Key Relation:\n",
        "\n",
        "* The **CLT** makes the **normal distribution** a powerful tool for inference, because it allows us to assume normality for the sample mean, even if the data itself is not normally distributed. This is crucial for statistical tests and confidence intervals.\n"
      ],
      "metadata": {
        "id": "5WJjt7SuaqYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q15.What is the application of Z statistics in hypothesis testing?\n",
        "- **Z-statistics** are used in **hypothesis testing** to determine how far a sample mean is from the population mean in terms of standard deviations. It is calculated using the **standard normal distribution**.\n",
        "\n",
        "### Application:\n",
        "\n",
        "* **Null Hypothesis Testing**: In a **z-test**, the Z-statistic helps decide whether to **reject or fail to reject** the null hypothesis based on the computed z-value and the chosen significance level (α).\n",
        "* It is commonly used when the sample size is large (typically $n > 30$) or when the population standard deviation is known.\n",
        "* **Critical value comparison**: The computed Z-value is compared with a critical value from the Z-table to assess the probability of observing the data under the null hypothesis.\n"
      ],
      "metadata": {
        "id": "Sa3nBEjgay7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q16. How do you calculate a Z-score, and what does it represent?\n",
        "- The **Z-score** measures how many standard deviations a data point is from the **mean** of a distribution. It is calculated using the formula:\n",
        "\n",
        "$$\n",
        "Z = \\frac{X - \\mu}{\\sigma}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $X$ = the value of the data point,\n",
        "* $\\mu$ = the mean of the population,\n",
        "* $\\sigma$ = the standard deviation of the population.\n",
        "\n",
        "### What it represents:\n",
        "\n",
        "* A **Z-score** tells you how far and in which direction (positive or negative) a data point deviates from the mean.\n",
        "* **Positive Z-score**: The data point is above the mean.\n",
        "* **Negative Z-score**: The data point is below the mean.\n"
      ],
      "metadata": {
        "id": "CUhabMIVa-h2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q17.= What are point estimates and interval estimates in statistics?\n",
        "In statistics:\n",
        "\n",
        "* **Point Estimate**: A single value that serves as an estimate of an unknown population parameter (e.g., the sample mean as a point estimate for the population mean). It provides a precise estimate but doesn't reflect the uncertainty.\n",
        "\n",
        "* **Interval Estimate**: A range of values, usually expressed as a **confidence interval**, within which the true population parameter is likely to fall. It provides more information by accounting for the uncertainty in the estimate.\n",
        "\n",
        "### Example:\n",
        "\n",
        "* **Point Estimate**: The sample mean $\\bar{X} = 50$.\n",
        "* **Interval Estimate**: A 95% confidence interval $[48, 52]$, meaning the population mean is likely between 48 and 52 with 95% confidence.\n"
      ],
      "metadata": {
        "id": "_jb2RxuvbIr4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q18.What is the significance of confidence intervals in statistical analysis?\n",
        "- **Confidence intervals (CIs)** provide a range of values that likely contain the true population parameter, with a specified level of confidence (e.g., 95%).\n",
        "\n",
        "### Significance:\n",
        "\n",
        "* They **quantify uncertainty**: Instead of giving a single estimate, a CI reflects the reliability of the estimate.\n",
        "* They are used to assess the **precision** of sample estimates, such as means or proportions.\n",
        "* A wider CI indicates more uncertainty, while a narrower CI suggests more confidence in the estimate.\n",
        "\n",
        "For example, a 95% CI means that if we repeat the sampling process many times, 95% of the intervals will contain the true parameter.\n"
      ],
      "metadata": {
        "id": "zDtE485CbROR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q19.What is the relationship between a Z-score and a confidence interval?\n",
        "- The **Z-score** and **confidence interval** are related in that the Z-score is used to calculate the **margin of error** when constructing a confidence interval for a population parameter.\n",
        "\n",
        "### Relationship:\n",
        "\n",
        "* The Z-score represents how many standard deviations a data point is from the mean.\n",
        "* For a given confidence level (e.g., 95%), the Z-score provides the critical value that determines the width of the confidence interval.\n",
        "\n",
        "For example, for a **95% confidence interval**, the Z-score is typically **1.96**, which corresponds to the point where 95% of the values lie within ±1.96 standard deviations from the mean.\n",
        "\n",
        "**Confidence Interval Formula**:\n",
        "\n",
        "$$\n",
        "\\text{CI} = \\text{sample mean} \\pm Z \\times \\frac{\\sigma}{\\sqrt{n}}\n",
        "$$\n",
        "\n",
        "where $Z$ is the Z-score for the desired confidence level.\n"
      ],
      "metadata": {
        "id": "DhHoap_JbaJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q20.How are Z-scores used to compare different distributions?\n",
        "- **Z-scores** standardize values from different distributions, allowing for **comparison across different scales** and **units**.\n",
        "\n",
        "### Usage in Comparison:\n",
        "\n",
        "* A **Z-score** tells you how many standard deviations a value is from its **own distribution's mean**.\n",
        "* By converting different data points to Z-scores, you can compare them even if they come from different distributions with different means and standard deviations.\n",
        "\n",
        "For example, if one distribution has a mean of 50 and a standard deviation of 5, and another has a mean of 100 and a standard deviation of 20, comparing the raw values directly might be misleading. But by calculating the Z-scores for each, you can compare how far each value is from its respective mean in standard deviation units.\n"
      ],
      "metadata": {
        "id": "nNuLQjqEbi_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q21.What are the assumptions for applying the Central Limit Theorem?\n",
        "- The **Central Limit Theorem (CLT)** applies under the following assumptions:\n",
        "\n",
        "1. **Independence**: The samples must be independent of each other.\n",
        "2. **Random Sampling**: The data should be randomly sampled from the population.\n",
        "3. **Sample Size**: The sample size $n$ should be sufficiently large (typically $n \\geq 30$ is considered large enough). For populations with a highly skewed distribution, a larger sample size may be needed.\n",
        "4. **Finite Variance**: The population from which the sample is drawn should have a finite variance.\n",
        "\n",
        "These assumptions ensure that the sampling distribution of the sample mean approaches a normal distribution, regardless of the original population's shape.\n"
      ],
      "metadata": {
        "id": "Dhfj_n2Vbr58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q22.What is the concept of expected value in a probability distribution?\n",
        "- The **expected value (EV)**, or **mean**, of a probability distribution is the **long-term average** or **center of gravity** of the distribution. It represents the weighted average of all possible outcomes, where each outcome is weighted by its probability.\n",
        "\n",
        "### Formula:\n",
        "\n",
        "For a discrete random variable:\n",
        "\n",
        "$$\n",
        "E(X) = \\sum_{i} P(x_i) \\cdot x_i\n",
        "$$\n",
        "\n",
        "For a continuous random variable:\n",
        "\n",
        "$$\n",
        "E(X) = \\int_{-\\infty}^{\\infty} x \\cdot f(x) \\, dx\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $P(x_i)$ is the probability of outcome $x_i$,\n",
        "* $f(x)$ is the probability density function.\n",
        "\n",
        "The expected value gives a sense of the \"average\" outcome you would expect if an experiment were repeated many times.\n"
      ],
      "metadata": {
        "id": "59_2h_tJbzB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q23.How does a probability distribution relate to the expected outcome of a random variable?\n",
        "- A **probability distribution** defines the likelihood of all possible outcomes for a random variable. The **expected value** is the **weighted average** of these outcomes, with each outcome weighted by its probability.\n",
        "\n",
        "In simple terms, the **expected value** is the \"center\" or **average** of the distribution, representing the long-term average outcome if the experiment were repeated many times. It is calculated using the probability distribution of the random variable.\n"
      ],
      "metadata": {
        "id": "CC-LpXfFb7mX"
      }
    }
  ]
}